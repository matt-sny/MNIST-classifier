{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97629d97",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import numpy as np\n",
    "from nn_classes import SimpleCNN\n",
    "from data_visualizer import plot_loss_accuracy, plot_confusion_matrix, display_images\n",
    "from nn_trainer import train_model, test_model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e0867",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e342095",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # mean & std for MNIST\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793327a3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create datasets and DataLoader objects\n",
    "train_dataset_full = MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_dataset, val_dataset = random_split(train_dataset_full, [50000, 10000])\n",
    "test_dataset = MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5586b1d0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define model, loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd49f5f3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Train model & validate\n",
    "n_epochs = 10\n",
    "train_accuracies, train_losses, val_accuracies, val_losses = train_model(model, train_loader=train_loader, val_loader=val_loader, criterion=criterion, optimizer=optimizer, n_epochs=n_epochs)\n",
    "if os.path.exists(\"best_model.pth\"):\n",
    "    model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "else:\n",
    "    raise FileNotFoundError(\"No pre-trained model found.\")\n",
    "test_accuracy, test_loss = test_model(model, test_loader=test_loader, criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df10d897",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Predict n_pred values\n",
    "n_pred = len(test_dataset)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_images = [test_dataset[i][0] for i in range(n_pred)]\n",
    "    true_labels = [test_dataset[i][1] for i in range(n_pred)]\n",
    "    sample_images = torch.stack(sample_images)\n",
    "    outputs = model(sample_images)\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "predictions = predictions.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c16b1dd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Get wrong predictions\n",
    "wrong_predictions = [pred != true for pred, true in zip(predictions, true_labels)]\n",
    "wrong_indices = [i for i, is_wrong in enumerate(wrong_predictions) if is_wrong]\n",
    "wrong_guesses = [predictions[i] for i in wrong_indices]\n",
    "print(f\"Total samples: {len(predictions)} | Misclassified: {len(wrong_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b1aa22",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "plot_loss_accuracy(train_losses, val_losses, train_accuracies, val_accuracies)\n",
    "plot_confusion_matrix(model, test_loader)\n",
    "display_images([test_dataset[i] for i in wrong_indices[:20]], predictions=wrong_guesses[:20])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
